{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YW8wMHfn6nFz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_m4O4gac8BrU"
   },
   "outputs": [],
   "source": [
    "# Defining our basic neural netowrk layers\n",
    "\n",
    "# Linear Layer\n",
    "class MyLinear():\n",
    "    def __init__(self, in_features, out_features):\n",
    "        # Initialization of the parameters (Weights and Bias)\n",
    "        self.W = np.random.randn(*(in_features,out_features)) / out_features\n",
    "        self.b = np.random.randn(*(out_features,)) / out_features\n",
    "    def __call__(self,x):\n",
    "        return self.forward(x)\n",
    "    def forward(self, x):\n",
    "        # Caching the input\n",
    "        self.x = x\n",
    "        # Calculating the output \n",
    "        # o = x W + b\n",
    "        self.o = x @ self.W + self.b\n",
    "        return self.o\n",
    "    def backward(self, grad_L):\n",
    "        # Calculating the gradient of the loss with respect to each parameter and the input\n",
    "        # Using the gradient of the loss with respect to the output as input\n",
    "        # grad_L_W = grad_L_O grad_O_W\n",
    "        self.grad_W = self.x.T @ grad_L  \n",
    "        # grad_L_b = grad_L_O grad_O_b\n",
    "        self.grad_b = np.sum(grad_L,axis=0)\n",
    "        # grad_L_x = grad_L_O grad_O_x\n",
    "        grad_x = grad_L @ self.W.T\n",
    "        return grad_x\n",
    "    def step(self,optim):\n",
    "        # Optimizing the parameters using the gradients\n",
    "        self.W = optim.step(self.W, self.grad_W)\n",
    "        self.b = optim.step(self.b, self.grad_b)\n",
    "\n",
    "# Sigmoid Layer (activation function)\n",
    "class MySigmoid():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self,x):\n",
    "        return self.forward(x)\n",
    "    def forward(self, x):\n",
    "        self.o = 1 / (1 + np.exp(-x))\n",
    "        return self.o\n",
    "    def backward(self, grad_L):\n",
    "        return (self.o) * (1 - self.o) * grad_L\n",
    "    def step(self,optim):\n",
    "        pass\n",
    "\n",
    "# Tanh Layer (activation function)\n",
    "class MyTanh():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self,x):\n",
    "        return self.forward(x)\n",
    "    def forward(self, x):\n",
    "        self.o = (1 - np.exp(-x)) / (1 + np.exp(-x))\n",
    "        return self.o\n",
    "    def backward(self, grad_L):\n",
    "        return (1 - self.o** 2) / 2  * grad_L\n",
    "    def step(self,optim):\n",
    "        pass\n",
    "\n",
    "# Sequential model\n",
    "class MySequential():\n",
    "    def __init__(self,layers=[]):\n",
    "        self.layers = layers\n",
    "    def __call__(self,x):\n",
    "        return self.forward(x)\n",
    "    def forward(self, x):\n",
    "        o = x\n",
    "        for l in self.layers:\n",
    "            o = l.forward(o)\n",
    "        return o\n",
    "    def backward(self, grad_L):\n",
    "        for l in reversed(self.layers):\n",
    "            grad_L = l.backward(grad_L)\n",
    "    def step(self, optim):\n",
    "        for l in self.layers:\n",
    "            l.step(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i1TxanikQCTp"
   },
   "outputs": [],
   "source": [
    "# Optimizer SGD (Stochastic Gradient Descent)\n",
    "class MySGD():\n",
    "    def __init__(self, lr=0.1):\n",
    "        self.lr = lr\n",
    "    def step(self, w, grad_w):\n",
    "        return w - self.lr * grad_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EHr6HY4X-Oc2"
   },
   "outputs": [],
   "source": [
    "# MSE Loss function (Mean Square Erro Loss)\n",
    "class MyMSELoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self,o,t):\n",
    "        N = len(o)\n",
    "        loss = np.sum((o - t) ** 2 / 2) / N\n",
    "        grad_loss = (o - t) / N\n",
    "        return loss, grad_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_sqHotFZMK6q"
   },
   "outputs": [],
   "source": [
    "class MyDataset():\n",
    "    def __init__(self,x,y,batch_size=10):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        N = len(self.x)\n",
    "        self.my_size = int(np.ceil(N / batch_size))\n",
    "    def __len__(self):\n",
    "        return self.my_size\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx * self.batch_size:(idx + 1) * self.batch_size], self.y[idx * self.batch_size:(idx + 1) * self.batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AyTHdhsC8J8N"
   },
   "outputs": [],
   "source": [
    "# Simple Sample: XOR \n",
    "\n",
    "# Data\n",
    "train_x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "train_y = np.array([[1,0],[0,1],[0,1],[1,0]])\n",
    "\n",
    "train_ds = MyDataset(train_x, train_y,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lfu_hgFjuAPM"
   },
   "outputs": [],
   "source": [
    "# Defining model, optimizer and loss function\n",
    "model = MySequential(layers=[\n",
    "    MyLinear(2,3),\n",
    "    MyTanh(),\n",
    "    MyLinear(3,2)\n",
    "])\n",
    "\n",
    "optim = MySGD(lr=0.5)\n",
    "crit = MyMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8o0QPi9QuQJy",
    "outputId": "da4cf0aa-266d-4826-feb7-c1b380399886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4201442619764585\n",
      "0.2641425523771533\n",
      "0.2574638648335259\n",
      "0.2565894122810018\n",
      "0.25606912752716277\n",
      "0.25561925631405413\n",
      "0.2552118132372963\n",
      "0.2548401043627225\n",
      "0.25450014375255103\n",
      "0.2541886578768792\n"
     ]
    }
   ],
   "source": [
    "# Training for 10 epochs\n",
    "for epoch in range(10):\n",
    "    avg_l = 0\n",
    "    for i in range(len(train_ds)):\n",
    "        x,y = train_ds[i]\n",
    "        o = model(x)\n",
    "        l,g_l = crit(o, y)\n",
    "        model.backward(g_l)\n",
    "        model.step(optim)\n",
    "        avg_l += l\n",
    "    print(avg_l / len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_ljMGkaK8R5",
    "outputId": "a80c72fe-00ac-4b1b-dc4b-6de85254f9e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model(train_x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yiTXkR4GLOqr",
    "outputId": "89c5300b-ff5b-41ea-800a-95dfbcab5f8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5007766 , 0.38772255],\n",
       "       [0.43674275, 0.52615266],\n",
       "       [0.56698474, 0.46623191],\n",
       "       [0.50254359, 0.60212222]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0IAuhec8P0me"
   },
   "outputs": [],
   "source": [
    "# Simple Sample: digits\n",
    "\n",
    "# Data\n",
    "raw_data = load_digits()\n",
    "\n",
    "data_images = raw_data[\"images\"].reshape((-1,8 * 8)) / 15.0\n",
    "data_target = raw_data[\"target\"]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_images, data_target,train_size=0.8)\n",
    "\n",
    "n = len(train_x)\n",
    "train_y_proc = np.zeros((n,10))\n",
    "train_y_proc[np.arange(n),train_y] = 1\n",
    "\n",
    "train_ds = MyDataset(train_x,train_y_proc,batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7AhklIcV8Mar"
   },
   "outputs": [],
   "source": [
    "# Defining model, optimizer and loss function\n",
    "model = MySequential(layers=[\n",
    "    MyLinear(64,32),\n",
    "    MyTanh(),\n",
    "    MyLinear(32,16),\n",
    "    MyTanh(),\n",
    "    MyLinear(16,10),\n",
    "])\n",
    "\n",
    "optim = MySGD(lr=0.5)\n",
    "crit = MyMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Og753Cq4U5U9",
    "outputId": "e3f6df36-d1a9-4941-97f4-db62ac6bf8e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16193891196854265\n",
      "0.16190632873003202\n",
      "0.16218198148882793\n",
      "0.16018446684287496\n",
      "0.15437777542960485\n",
      "0.15100263030624134\n",
      "0.16194737561185132\n",
      "0.1509100801948943\n",
      "0.15453346750119673\n",
      "0.15718901115207567\n"
     ]
    }
   ],
   "source": [
    "# Training for 10 epochs\n",
    "for epoch in range(10):\n",
    "    avg_loss = 0\n",
    "    for i in range(len(train_ds)):\n",
    "        x,y = train_ds[i]\n",
    "        o = model(x)\n",
    "        l,g_l = crit(o, y)\n",
    "        model.backward(g_l)\n",
    "        model.step(optim)\n",
    "        avg_loss += l\n",
    "    print(avg_loss / len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLXRNd0FVHv-",
    "outputId": "fb295428-45a4-4925-d244-b67fa325e91d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 3, 2, 9, 0, 6, 8, 0, 3, 6, 4, 1, 6, 3, 8, 2, 7, 5, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model(train_x[:20]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXFDNdlCIGoC",
    "outputId": "700bd6f2-8b44-46c4-96de-a312295dd6df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 3, 2, 9, 0, 6, 8, 0, 3, 6, 4, 1, 6, 3, 8, 3, 7, 5, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGHUA19rWQRl",
    "outputId": "cfc29100-2181-47a9-f381-dd6005dc8e27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(model(train_x),axis=1) == train_y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
